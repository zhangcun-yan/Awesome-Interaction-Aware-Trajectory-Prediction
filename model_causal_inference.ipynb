{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNEp/cpK7mdpfTicAhYBwBv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangcun-yan/Awesome-Interaction-Aware-Trajectory-Prediction/blob/master/model_causal_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip show scikit-learn"
      ],
      "metadata": {
        "id": "UMNTyp6vPwGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gcastle"
      ],
      "metadata": {
        "id": "733F8QosRzm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall networkx"
      ],
      "metadata": {
        "id": "MAZWdhMtR2iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install networkx==2.8.0"
      ],
      "metadata": {
        "id": "REcjdL5fR8N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "import os\n",
        "os.environ['CASTLE_BACKEND'] = 'pytorch'\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from scipy import linalg\n",
        "# from sklearnear_model import LinearRegression\n",
        "import castle\n",
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.algorithms import PC, GES\n",
        "from castle.algorithms import ANMNonlinear, ICALiNGAM, DirectLiNGAM\n",
        "from castle.algorithms import Notears, NotearsNonlinear, GOLEM\n",
        "from castle.common.priori_knowledge import PrioriKnowledge\n",
        "from castle.common.independence_tests import hsic_test\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "__WnbbAYPkwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLORS = [\n",
        "    '#00B0F0',\n",
        "    '#FF0000',\n",
        "    '#B0F000'\n",
        "]"
      ],
      "metadata": {
        "id": "b9sokCT1QoEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "SEED = 18\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "3xkVkxWrQt1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a scale-free adjacency matrix\n",
        "adj_matrix = DAG.scale_free(\n",
        "    n_nodes=10,\n",
        "    n_edges=17,\n",
        "    seed=SEED\n",
        ")"
      ],
      "metadata": {
        "id": "yeuC1x-mQvue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the adjacency matrix\n",
        "g = nx.DiGraph(adj_matrix) # convert the matrix into graph\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw_networkx(\n",
        "    G=g, # graph\n",
        "    node_color=COLORS[0],\n",
        "    node_size=1200,\n",
        "    arrowsize=17,\n",
        "    with_labels=True,\n",
        "    font_color='white',\n",
        "    font_size=21,\n",
        "    pos=nx.circular_layout(g)\n",
        ")"
      ],
      "metadata": {
        "id": "wy99YWvlQxpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1e_jQ8KPU_E"
      },
      "outputs": [],
      "source": [
        "# notear\n",
        "df_causal = pd.read_csv('./ttc_event_var.csv')\n",
        "df_causal = pd.DataFrame(df_causal)\n",
        "# df_causal = df_causal.drop(columns=['slope_ttc'])\n",
        "df_causal.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PC"
      ],
      "metadata": {
        "id": "PPAOVKpiRMHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.algorithms import PC\n",
        "from castle.common.priori_knowledge import PrioriKnowledge\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw"
      ],
      "metadata": {
        "id": "_MdjRXmoRLZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "method = 'linear'\n",
        "sem_type = 'gauss'\n",
        "n_nodes = df_causal.shape[1]\n",
        "n_edges = 10\n",
        "n = 20000"
      ],
      "metadata": {
        "id": "WjkOTxbCRTD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_causal.columns"
      ],
      "metadata": {
        "id": "7LT2z2SuSa5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc = PC(variant='original',alpha=0.001)\n",
        "pc.learn(df_causal)\n",
        "pc.causal_matrix\n",
        "# Convert the matrix to a pandas DataFrame\n",
        "df = pd.DataFrame(pc.causal_matrix)\n",
        "# plot predict_dag and true_dag\n",
        "GraphDAG(pc.causal_matrix)"
      ],
      "metadata": {
        "id": "9FLGZDu22p0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = nx.DiGraph(pc.causal_matrix)\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw_networkx(\n",
        "    G=g,\n",
        "    node_color=COLORS[0],\n",
        "    node_size=1000,\n",
        "    arrowsize=8,\n",
        "    with_labels=True,\n",
        "    font_color='black',\n",
        "    font_size=20,\n",
        "    pos=nx.circular_layout(g)\n",
        ")"
      ],
      "metadata": {
        "id": "mMeDYTM32_s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simulation for pc\n",
        "weighted_random_dag = DAG.erdos_renyi(n_nodes=n_nodes, n_edges=n_edges, weight_range=(0.5,20), seed=1)\n",
        "X = df_causal\n",
        "\n",
        "# PC learn\n",
        "priori = PrioriKnowledge(X.shape[1])\n",
        "priori.add_required_edges([(1,0),(2,0),(3,0),(4,0),(5,0),(6,0),(7,0)])\n",
        "priori.add_forbidden_edges([(0,1),(0,3),(0,5),(0,6),(0,8),(0,4),(0,14),(1,14),(2,14),(3,14),(4,14),(5,14),(6,14),(7,14),(8,14),(9,14),(10,14),(11,14),(12,14),(13,14),(15,14),(16,14),(0,9),(1,9),(2,9),(3,9),(4,9),(5,9),(6,9),(7,9),(8,9),(14,9),(10,9),(11,9),(12,9),(13,9),(15,9),(16,9)])\n",
        "pc = PC(variant='original', priori_knowledge=priori,alpha=0.001)\n",
        "X = pd.DataFrame(X, columns=list(['ACT', 'DIS', 'D_MTC', 'D_NMTC','mv_v', 'nmv_v', 'mv_acc_m','nmv_acc_m', 'NDIR', 'MN_angle', 'mv_angle_M', 'nmv_angle_M','mv_angle_V', 'nmv_angle_V', 'light_pos', 'mv_env_entropy','nmv_env_entropy']))"
      ],
      "metadata": {
        "id": "7CZInZxORVmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc.learn(X)\n",
        "pc.causal_matrix\n",
        "# Convert the matrix to a pandas DataFrame\n",
        "df = pd.DataFrame(pc.causal_matrix)\n",
        "# plot predict_dag and true_dag\n",
        "GraphDAG(pc.causal_matrix)"
      ],
      "metadata": {
        "id": "VkyuUWsURe4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLORS = [\n",
        "    '#00B0F0',\n",
        "    '#FF0000',\n",
        "    '#B0F000'\n",
        "]"
      ],
      "metadata": {
        "id": "etuH1gJjRlwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = nx.DiGraph(pc.causal_matrix)\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw_networkx(\n",
        "    G=g,\n",
        "    node_color=COLORS[0],\n",
        "    node_size=1000,\n",
        "    arrowsize=8,\n",
        "    with_labels=True,\n",
        "    font_color='black',\n",
        "    font_size=20,\n",
        "    pos=nx.circular_layout(g)\n",
        ")\n",
        "# plt.savefig(r'D:\\dataset\\Intersection\\Data_processing\\model\\Variable_importance\\figure/nt_pc.pdf', format='pdf')"
      ],
      "metadata": {
        "id": "Fv0W2skwRn8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GES"
      ],
      "metadata": {
        "id": "fAXTIQJqXryc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "from castle.algorithms.ges.ges import GES\n",
        "\n",
        "X = df_causal\n",
        "\n",
        "for d in [3, 6, 9, 12, 15]:\n",
        "    edges = d * 2\n",
        "    weighted_random_dag = DAG.erdos_renyi(n_nodes=d, n_edges=edges,\n",
        "                                          weight_range=(0.005, 2.00), seed=1)\n",
        "    # dataset = IIDSimulation(W=weighted_random_dag, n=1000,\n",
        "    #                         method='nonlinear', sem_type='gp-add')\n",
        "    # true_dag, X = dataset.B, dataset.X\n",
        "    algo = GES(criterion='bic',method='scatter')\n",
        "    algo.learn(X)\n",
        "\n",
        "    # plot predict_dag and true_dag\n",
        "    GraphDAG(algo.causal_matrix)\n",
        "    # m1 = MetricsDAG(algo.causal_matrix)\n",
        "    # print(m1.metrics)\n",
        "    break"
      ],
      "metadata": {
        "id": "DzXN49H-Xv77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = nx.DiGraph(algo.causal_matrix)\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw_networkx(\n",
        "    G=g,\n",
        "    node_color=COLORS[0],\n",
        "    node_size=1200,\n",
        "    arrowsize=17,\n",
        "    with_labels=True,\n",
        "    font_color='white',\n",
        "    font_size=21,\n",
        "    pos=nx.circular_layout(g)\n",
        ")"
      ],
      "metadata": {
        "id": "UPQ3qn_xbG6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ges = GES(criterion='bic',method='scatter')\n",
        "ges.learn(X)"
      ],
      "metadata": {
        "id": "x-MerPQTX1IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GraphDAG(ges.causal_matrix)"
      ],
      "metadata": {
        "id": "r28So4moX13s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = nx.DiGraph(ges.causal_matrix)\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw_networkx(\n",
        "    G=g,\n",
        "    node_color=COLORS[0],\n",
        "    node_size=1200,\n",
        "    arrowsize=17,\n",
        "    with_labels=True,\n",
        "    font_color='white',\n",
        "    font_size=21,\n",
        "    pos=nx.circular_layout(g)\n",
        ")"
      ],
      "metadata": {
        "id": "TzpycEM4X4TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## golem"
      ],
      "metadata": {
        "id": "H5HcanarbbNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.algorithms import GOLEM\n",
        "\n",
        "\n",
        "#######################################\n",
        "# GOLEM used simulate data\n",
        "#######################################\n",
        "# simulate data for GOLEM\n",
        "weighted_random_dag = DAG.erdos_renyi(n_nodes=df_causal.shape[1], n_edges=20, weight_range=(0.5, 2.0), seed=1)\n",
        "\n",
        "# dataset = IIDSimulation(W=weighted_random_dag, n=2000, method='linear', sem_type='gauss')\n",
        "# true_dag, X = dataset.B, dataset.X\n",
        "\n",
        "# GOLEM learn\n",
        "g = GOLEM(num_iter=1e4)\n",
        "g.learn(df_causal)\n",
        "\n",
        "# plot est_dag and true_dag\n",
        "GraphDAG(g.causal_matrix)"
      ],
      "metadata": {
        "id": "rJ4XDq24bdg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = nx.DiGraph(g.causal_matrix)\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw_networkx(\n",
        "    G=g,\n",
        "    node_color=COLORS[2],\n",
        "    node_size=1200,\n",
        "    arrowsize=17,\n",
        "    with_labels=True,\n",
        "    font_color='white',\n",
        "    font_size=21,\n",
        "    pos=nx.circular_layout(g)\n",
        ")"
      ],
      "metadata": {
        "id": "kwjaR61QbgoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nonlinear"
      ],
      "metadata": {
        "id": "ywhvhNjpVd8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "import os\n",
        "os.environ['CASTLE_BACKEND'] = 'pytorch'\n",
        "\n",
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.algorithms import NotearsNonlinear\n",
        "\n",
        "\n",
        "#######################################\n",
        "# notears-nonlinear used simulate data\n",
        "#######################################\n",
        "# simulate data for notears-nonlinear\n",
        "weighted_random_dag = DAG.erdos_renyi(n_nodes=df_causal.shape[1], n_edges=20, weight_range=(0.5, 2.0), seed=1)\n",
        "# dataset = IIDSimulation(W=weighted_random_dag, n=2000, method='nonlinear', sem_type='mlp')\n",
        "# true_dag, X = dataset.B, dataset.X\n",
        "\n",
        "# notears-nonlinear learn\n",
        "nt = NotearsNonlinear()\n",
        "nt.learn(df_causal)\n",
        "\n",
        "# plot est_dag and true_dag\n",
        "GraphDAG(nt.causal_matrix)"
      ],
      "metadata": {
        "id": "nPgQ2e98Pa2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = nx.DiGraph(nt.causal_matrix)\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw_networkx(\n",
        "    G=g,\n",
        "    node_color=COLORS[2],\n",
        "    node_size=1200,\n",
        "    arrowsize=17,\n",
        "    with_labels=True,\n",
        "    font_color='white',\n",
        "    font_size=21,\n",
        "    pos=nx.circular_layout(g)\n",
        ")"
      ],
      "metadata": {
        "id": "T9F2zuwjVxQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_7T-LAz-Vvw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  DAG_gnn"
      ],
      "metadata": {
        "id": "C04Nl7WGV3ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CASTLE_BACKEND'] ='pytorch'\n",
        "\n",
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.algorithms import DAG_GNN\n",
        "\n",
        "\n",
        "type = 'ER'  # or `SF`\n",
        "h = 2  # ER2 when h=5 --> ER5\n",
        "n_nodes = df_causal.shape[1]\n",
        "n_edges = h * n_nodes\n",
        "method = 'linear'\n",
        "sem_type = 'gauss'\n",
        "\n",
        "if type == 'ER':\n",
        "    weighted_random_dag = DAG.erdos_renyi(n_nodes=n_nodes, n_edges=n_edges,\n",
        "                                          weight_range=(0.5, 2.0), seed=300)\n",
        "elif type == 'SF':\n",
        "    weighted_random_dag = DAG.scale_free(n_nodes=n_nodes, n_edges=n_edges,\n",
        "                                         weight_range=(0.5, 2.0), seed=300)\n",
        "else:\n",
        "    raise ValueError('Just supported `ER` or `SF`.')\n",
        "\n",
        "# dataset = IIDSimulation(W=weighted_random_dag, n=2000,\n",
        "#                         method=method, sem_type=sem_type)\n",
        "# true_dag, X = dataset.B, dataset.X\n",
        "\n",
        "# rl learn\n",
        "gnn = DAG_GNN()\n",
        "gnn.learn(df_causal)\n",
        "\n",
        "# plot est_dag and true_dag\n",
        "GraphDAG(gnn.causal_matrix)"
      ],
      "metadata": {
        "id": "b3SUR5XQsEEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = nx.DiGraph(gnn.causal_matrix)\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw_networkx(\n",
        "    G=g,\n",
        "    node_color=COLORS[0],\n",
        "    node_size=1200,\n",
        "    arrowsize=17,\n",
        "    with_labels=True,\n",
        "    font_color='white',\n",
        "    font_size=21,\n",
        "    pos=nx.circular_layout(g)\n",
        ")"
      ],
      "metadata": {
        "id": "PZ5LJt29Ww6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h9ElsdfIWzsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MCSL"
      ],
      "metadata": {
        "id": "0aw70pI8rzDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.algorithms import MCSL\n",
        "\n",
        "\n",
        "#######################################\n",
        "# mcsl used simulate data\n",
        "#######################################\n",
        "# simulate data for mcsl\n",
        "weighted_random_dag = DAG.erdos_renyi(n_nodes=df_causal.shape[1], n_edges=20, weight_range=(0.5, 2.0), seed=1)\n",
        "# dataset = IIDSimulation(W=weighted_random_dag, n=2000, method='nonlinear', sem_type='mlp')\n",
        "# true_dag, X = dataset.B, dataset.X\n",
        "\n",
        "# mcsl learn\n",
        "mc = MCSL(model_type='nn',\n",
        "          iter_step=10000,\n",
        "          rho_thresh=1e20,\n",
        "          init_rho=1e-5,\n",
        "          rho_multiply=10,\n",
        "          graph_thresh=0.5,\n",
        "          l1_graph_penalty=2e-3)\n",
        "mc.learn(df_causal)\n",
        "\n",
        "# plot est_dag and true_dag\n",
        "GraphDAG(mc.causal_matrix)"
      ],
      "metadata": {
        "id": "9nAE4o-6WzFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = nx.DiGraph(mc.causal_matrix)\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw_networkx(\n",
        "    G=g,\n",
        "    node_color=COLORS[2],\n",
        "    node_size=1200,\n",
        "    arrowsize=17,\n",
        "    with_labels=True,\n",
        "    font_color='white',\n",
        "    font_size=21,\n",
        "    pos=nx.circular_layout(g)\n",
        ")"
      ],
      "metadata": {
        "id": "sKzdryNbXRWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = nx.DiGraph(nt.causal_matrix)\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw_networkx(\n",
        "    G=g,\n",
        "    node_color=COLORS[2],\n",
        "    node_size=1200,\n",
        "    arrowsize=17,\n",
        "    with_labels=True,\n",
        "    font_color='white',\n",
        "    font_size=21,\n",
        "    pos=nx.circular_layout(g)\n",
        ")"
      ],
      "metadata": {
        "id": "bMn4gRmHYE3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RL**"
      ],
      "metadata": {
        "id": "bg09a5jmYN9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.algorithms import RL\n",
        "import pandas as pd\n",
        "\n",
        "#######################################\n",
        "# rl used simulate data\n",
        "#######################################\n",
        "# simulate data for rl\n",
        "weighted_random_dag = DAG.erdos_renyi(n_nodes=df_causal.shape[1], n_edges=df_causal.shape[1]*2, weight_range=(0.5, 2.0), seed=1)\n",
        "# dataset = IIDSimulation(W=weighted_random_dag, n=2000, method='linear', sem_type='gauss')\n",
        "# true_dag, X = dataset.B, dataset.X\n",
        "\n",
        "# rl learn\n",
        "rl = RL(nb_epoch=2000)\n",
        "\n",
        "rl.learn(df_causal)\n",
        "\n",
        "# plot est_dag and true_dag\n",
        "GraphDAG(rl.causal_matrix)"
      ],
      "metadata": {
        "id": "WT7YBhvSYNdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = nx.DiGraph(rl.causal_matrix)\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw_networkx(\n",
        "    G=g,\n",
        "    node_color=COLORS[0],\n",
        "    node_size=1200,\n",
        "    arrowsize=17,\n",
        "    with_labels=True,\n",
        "    font_color='white',\n",
        "    font_size=21,\n",
        "    pos=nx.circular_layout(g)\n",
        ")"
      ],
      "metadata": {
        "id": "iyZGJ_YbYirO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRAN_dag"
      ],
      "metadata": {
        "id": "M2rtTIMa1WXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.algorithms import GraNDAG\n",
        "import pandas as pd\n",
        "# load data\n",
        "weighted_random_dag = DAG.erdos_renyi(n_nodes=df_causal.shape[1], n_edges=df_causal.shape[1]*2,\n",
        "                                      weight_range=(0.5, 2.0), seed=1)\n",
        "# dataset = IIDSimulation(W=weighted_random_dag, n=2000, method='nonlinear',\n",
        "#                         sem_type='mlp')\n",
        "# dag, x = dataset.B, dataset.X\n",
        "\n",
        "# Instantiation algorithm\n",
        "d = {'model_name': 'NonLinGauss', 'nonlinear': 'leaky-relu', 'optimizer': 'sgd', 'norm_prod': 'paths', 'device_type': 'gpu'}\n",
        "gnd = GraNDAG(input_dim=x.shape[1], )\n",
        "\n",
        "# gnd.learn(data=data)\n",
        "gnd.learn(df_causal)\n",
        "\n",
        "# plot predict_dag and true_dag\n",
        "GraphDAG(gnd.causal_matrix, dag)"
      ],
      "metadata": {
        "id": "dfXlOPf21Zbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MCSL"
      ],
      "metadata": {
        "id": "ECKTEr4J1smn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from castle.metrics import MetricsDAG\n",
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.algorithms import MCSL\n",
        "\n",
        "\n",
        "#######################################\n",
        "# mcsl used simulate data\n",
        "#######################################\n",
        "# simulate data for mcsl\n",
        "weighted_random_dag = DAG.erdos_renyi(n_nodes=df_causal.shape[1], n_edges=df_causal.shape[1]*2, weight_range=(0.5, 2.0), seed=1)\n",
        "# dataset = IIDSimulation(W=weighted_random_dag, n=2000, method='nonlinear', sem_type='mlp')\n",
        "# true_dag, X = dataset.B, dataset.X\n",
        "\n",
        "# mcsl learn\n",
        "mc = MCSL(model_type='nn',\n",
        "          iter_step=100,\n",
        "          rho_thresh=1e20,\n",
        "          init_rho=1e-5,\n",
        "          rho_multiply=10,\n",
        "          graph_thresh=0.5,\n",
        "          l1_graph_penalty=2e-3)\n",
        "\n",
        "mc.learn(X)\n",
        "\n",
        "# plot est_dag and true_dag\n",
        "GraphDAG(mc.causal_matrix)"
      ],
      "metadata": {
        "id": "5qdIdwmB1v_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAE"
      ],
      "metadata": {
        "id": "wNcZeY9i2EQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.algorithms import GAE\n",
        "\n",
        "\n",
        "#######################################\n",
        "# graph_auto_encoder used simulate data\n",
        "#######################################\n",
        "# simulate data for graph-auto-encoder\n",
        "weighted_random_dag = DAG.erdos_renyi(n_nodes=df_causal.shape[1], n_edges=df_causal.shape[1]*2, weight_range=(0.5, 2.0), seed=1)\n",
        "# dataset = IIDSimulation(W=weighted_random_dag, n=2000, method='linear', sem_type='gauss')\n",
        "# true_dag, X = dataset.B, dataset.X\n",
        "\n",
        "ga = GAE(input_dim=10)\n",
        "ga.learn(df_causal)\n",
        "\n",
        "# plot est_dag and true_dag\n",
        "GraphDAG(ga.causal_matrix)"
      ],
      "metadata": {
        "id": "CM0e73XN2H5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CORL"
      ],
      "metadata": {
        "id": "2vdlu8ev2tLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.environ['CASTLE_BACKEND'] ='pytorch'\n",
        "\n",
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.algorithms import CORL\n",
        "\n",
        "type = 'ER'  # or `SF`\n",
        "h = 2  # ER2 when h=5 --> ER5\n",
        "n_nodes = df_causal.shape[1]\n",
        "n_edges = h * n_nodes\n",
        "method = 'linear'\n",
        "sem_type = 'gauss'\n",
        "\n",
        "if type == 'ER':\n",
        "    weighted_random_dag = DAG.erdos_renyi(n_nodes=n_nodes, n_edges=n_edges,\n",
        "                                          weight_range=(0.5, 2.0), seed=300)\n",
        "elif type == 'SF':\n",
        "    weighted_random_dag = DAG.scale_free(n_nodes=n_nodes, n_edges=n_edges,\n",
        "                                         weight_range=(0.5, 2.0), seed=300)\n",
        "else:\n",
        "    raise ValueError('Just supported `ER` or `SF`.')\n",
        "\n",
        "# dataset = IIDSimulation(W=weighted_random_dag, n=2000,\n",
        "#                         method=method, sem_type=sem_type)\n",
        "# true_dag, X = dataset.B, dataset.X\n",
        "\n",
        "# rl learn\n",
        "rl = CORL(encoder_name='transformer',\n",
        "          decoder_name='lstm',\n",
        "          reward_mode='episodic',\n",
        "          reward_regression_type='LR',\n",
        "          batch_size=64,\n",
        "          input_dim=64,\n",
        "          embed_dim=64,\n",
        "          iteration=2000,\n",
        "          device_type='GPU')\n",
        "rl.learn(df_causal)\n",
        "\n",
        "# plot est_dag and true_dag\n",
        "GraphDAG(rl.causal_matrix)"
      ],
      "metadata": {
        "id": "odamg0eE2wUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other method"
      ],
      "metadata": {
        "id": "Zh9WucZ73Hn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DECI IN Code"
      ],
      "metadata": {
        "id": "TD7vJowsqFbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from tensordict import TensorDict\n",
        "\n",
        "from castle.datasets import DAG, IIDSimulation\n",
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "\n",
        "import causica.distributions as cd\n",
        "\n",
        "from causica.functional_relationships import ICGNN\n",
        "from causica.training.auglag import AugLagLossCalculator, AugLagLR, AugLagLRConfig\n",
        "from causica.graph.dag_constraint import calculate_dagness\n",
        "\n",
        "from causica.datasets.variable_types import VariableTypeEnum\n",
        "from causica.datasets.tensordict_utils import tensordict_shapes\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "metadata": {
        "id": "3apgNbAcqJAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "E-hWwYQ2Efg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLORS = [\n",
        "    '#00B0F0',\n",
        "    '#FF0000',\n",
        "    '#B0F000'\n",
        "]"
      ],
      "metadata": {
        "id": "wSrSXfXWrHCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "SEED = 11\n",
        "np.random.seed(SEED)\n",
        "pl.seed_everything(SEED)"
      ],
      "metadata": {
        "id": "rk9NAHG1rHY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx.__version__"
      ],
      "metadata": {
        "id": "CUVAoBCzrHdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a scale-free adjacency matrix\n",
        "adj_matrix = DAG.scale_free(\n",
        "    n_nodes=4,\n",
        "    n_edges=6,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "# Generate the simulation\n",
        "dataset = IIDSimulation(\n",
        "    W=adj_matrix,\n",
        "    n=5000,\n",
        "    method='nonlinear',\n",
        "    sem_type='mim'\n",
        ")"
      ],
      "metadata": {
        "id": "guvicbt1rHgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the graph\n",
        "g = nx.DiGraph(adj_matrix)\n",
        "\n",
        "plt.figure(figsize=(4, 3))\n",
        "nx.draw(\n",
        "    G=g,\n",
        "    node_color=COLORS[0],\n",
        "    node_size=1200,\n",
        "    arrowsize=17,\n",
        "    with_labels=True,\n",
        "    font_color='white',\n",
        "    font_size=21,\n",
        "    pos=nx.circular_layout(g)\n",
        ")"
      ],
      "metadata": {
        "id": "d3Omlp2Iywkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training config\n",
        "@dataclass(frozen=True)\n",
        "class TrainingConfig:\n",
        "    noise_dist=cd.ContinuousNoiseDist.SPLINE\n",
        "    batch_size=512\n",
        "    max_epoch=500\n",
        "    gumbel_temp=0.25\n",
        "    averaging_period=10\n",
        "    prior_sparsity_lambda=5.0\n",
        "    init_rho=1.0\n",
        "    init_alpha=0.0\n",
        "\n",
        "training_config = TrainingConfig()\n",
        "auglag_config = AugLagLRConfig()"
      ],
      "metadata": {
        "id": "HVp37NmRyy13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cast data to torch tensors\n",
        "data_tensors = {}\n",
        "\n",
        "for i in range(dataset.X.shape[1]):\n",
        "    data_tensors[f'x{i}'] = torch.tensor(dataset.X[:, i].reshape(-1, 1))\n",
        "\n",
        "dataset_train = TensorDict(data_tensors, torch.Size([dataset.X.shape[0]]))\n",
        "\n",
        "# Move the entire dataset to the device (for big datasets move to device by batch within training loop)\n",
        "dataset_train = dataset_train.apply(lambda t: t.to(dtype=torch.float32, device=device))\n",
        "\n",
        "# Create loader\n",
        "dataloader_train = DataLoader(\n",
        "    dataset=dataset_train,\n",
        "    collate_fn=lambda x: x,\n",
        "    batch_size=training_config.batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "dataset_train"
      ],
      "metadata": {
        "id": "9Qa5Ntqfy1Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the true adj matrix\n",
        "plt.style.use('default')\n",
        "GraphDAG(adj_matrix)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5698MMoey3P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode our strong belief about the existence of the edge (3, 0)\n",
        "# And lack of existence of edge (0, 3)\n",
        "expert_matrix = torch.tensor(np.zeros(adj_matrix.shape))\n",
        "\n",
        "# Encode the edge knowledge\n",
        "expert_matrix[3, 0] = 1.\n",
        "\n",
        "# Create a relevancew mask\n",
        "relevance_mask = expert_matrix.clone()\n",
        "relevance_mask[0, 3] = 1.\n",
        "\n",
        "# Create a confidence matrix\n",
        "confidence_matrix = relevance_mask.clone()"
      ],
      "metadata": {
        "id": "L04GtSSuy5Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encapsulate everything within the expert knowledge container\n",
        "expert_knowledge = cd.ExpertGraphContainer(\n",
        "    dag=expert_matrix,\n",
        "    mask=relevance_mask,\n",
        "    confidence=confidence_matrix,\n",
        "    scale=5.\n",
        ")"
      ],
      "metadata": {
        "id": "xEJ0uf_6y7YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_nodes = len(dataset_train.keys())\n",
        "\n",
        "# Define the prior\n",
        "prior = cd.GibbsDAGPrior(\n",
        "    num_nodes=num_nodes,\n",
        "    sparsity_lambda=training_config.prior_sparsity_lambda,\n",
        "    expert_graph_container=expert_knowledge\n",
        ")"
      ],
      "metadata": {
        "id": "GNVHOuvKy9dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the adjaceny module\n",
        "adjacency_dist = cd.ENCOAdjacencyDistributionModule(num_nodes)\n",
        "\n",
        "#Define the functional module\n",
        "icgnn = ICGNN(\n",
        "    variables=tensordict_shapes(dataset_train),\n",
        "    embedding_size=8, #32,\n",
        "    out_dim_g=8, #32,\n",
        "    norm_layer=torch.nn.LayerNorm,\n",
        "    res_connection=True,\n",
        ")\n",
        "\n",
        "# Define the noise module\n",
        "types_dict = {var_name: VariableTypeEnum.CONTINUOUS for var_name in dataset_train.keys()}\n",
        "\n",
        "noise_submodules = cd.create_noise_modules(\n",
        "    shapes=tensordict_shapes(dataset_train),\n",
        "    types=types_dict,\n",
        "    continuous_noise_dist=training_config.noise_dist\n",
        ")\n",
        "\n",
        "noise_module = cd.JointNoiseModule(noise_submodules)"
      ],
      "metadata": {
        "id": "AEiWuQBFy_aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_submodules"
      ],
      "metadata": {
        "id": "GVYo7nXBy9lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "?cd.SEMDistributionModule"
      ],
      "metadata": {
        "id": "D8hLQc1iy9ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all SEM modules\n",
        "sem_module = cd.SEMDistributionModule(\n",
        "    adjacency_module=adjacency_dist,\n",
        "    functional_relationships=icgnn,\n",
        "    noise_module=noise_module)\n",
        "\n",
        "sem_module.to(device)"
      ],
      "metadata": {
        "id": "pYMh9Qbiy9rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modules = {\n",
        "    \"icgnn\": sem_module.functional_relationships,\n",
        "    \"vardist\": sem_module.adjacency_module,\n",
        "    \"noise_dist\": sem_module.noise_module,\n",
        "}\n",
        "\n",
        "parameter_list = [\n",
        "    {\"params\": module.parameters(), \"lr\": auglag_config.lr_init_dict[name], \"name\": name}\n",
        "    for name, module in modules.items()\n",
        "]\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(parameter_list)"
      ],
      "metadata": {
        "id": "70USjqS-zI0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the augmented Lagrangian loss objects\n",
        "scheduler = AugLagLR(config=auglag_config)\n",
        "\n",
        "auglag_loss = AugLagLossCalculator(\n",
        "    init_alpha=training_config.init_alpha,\n",
        "    init_rho=training_config.init_rho\n",
        ")"
      ],
      "metadata": {
        "id": "04iGPR7yzKFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(dataset_train.batch_size) == 1, \"Only 1D batch size is supported\"\n",
        "\n",
        "num_samples = len(dataset_train)\n",
        "\n",
        "for epoch in range(training_config.max_epoch):\n",
        "\n",
        "    for i, batch in enumerate(dataloader_train):\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get SEM\n",
        "        sem_distribution = sem_module()\n",
        "        sem, *_ = sem_distribution.relaxed_sample(\n",
        "            torch.Size([]),\n",
        "            temperature=training_config.gumbel_temp\n",
        "        )  # soft sample\n",
        "\n",
        "        # Compute the log probability of data\n",
        "        batch_log_prob = sem.log_prob(batch).mean()\n",
        "\n",
        "        # Get the distribution entropy\n",
        "        sem_distribution_entropy = sem_distribution.entropy()\n",
        "\n",
        "        # Compute the likelihood of the current graph\n",
        "        prior_term = prior.log_prob(sem.graph)\n",
        "\n",
        "        # Compute the objective\n",
        "        objective = (-sem_distribution_entropy - prior_term) / num_samples - batch_log_prob\n",
        "\n",
        "        # Compute the DAG-ness term\n",
        "        constraint = calculate_dagness(sem.graph)\n",
        "\n",
        "        # Compute the Lagrangian loss\n",
        "        loss = auglag_loss(objective, constraint / num_samples)\n",
        "\n",
        "        # Propagate gradients and update\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the Auglag parameters\n",
        "        scheduler.step(\n",
        "            optimizer=optimizer,\n",
        "            loss=auglag_loss,\n",
        "            loss_value=loss.item(),\n",
        "            lagrangian_penalty=constraint.item(),\n",
        "        )\n",
        "\n",
        "        # Log metrics & plot the matrices\n",
        "        if epoch % 10 == 0 and i == 0:\n",
        "            print(\n",
        "                f\"epoch:{epoch} loss:{loss.item():.5g} nll:{-batch_log_prob.detach().cpu().numpy():.5g} \"\n",
        "                f\"dagness:{constraint.item():.5f} num_edges:{(sem.graph > 0.0).sum()} \"\n",
        "                f\"alpha:{auglag_loss.alpha:.5g} rho:{auglag_loss.rho:.5g} \"\n",
        "                f\"step:{scheduler.outer_opt_counter}|{scheduler.step_counter} \"\n",
        "                f\"num_lr_updates:{scheduler.num_lr_updates}\"\n",
        "            )\n",
        "\n",
        "            vardist = adjacency_dist()\n",
        "            pred_dag = vardist.mode.cpu().numpy()\n",
        "\n",
        "            plt.style.use('default')\n",
        "\n",
        "            GraphDAG(\n",
        "                est_dag=pred_dag,\n",
        "                true_dag=adj_matrix)\n",
        "\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "wZqHUcYSzKJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample from the distribution of graphs\n",
        "vardist = adjacency_dist()\n",
        "pred_dag = vardist.mode.cpu().numpy()\n",
        "\n",
        "\n",
        "# Plot the final graph vs the ground truth\n",
        "plt.style.use('default')\n",
        "\n",
        "GraphDAG(\n",
        "    est_dag=pred_dag,\n",
        "    true_dag=adj_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P_mpyHKLzKNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and print the metrics\n",
        "metrics = MetricsDAG(\n",
        "    B_est=pred_dag,\n",
        "    B_true=adj_matrix)\n",
        "\n",
        "metrics.metrics"
      ],
      "metadata": {
        "id": "UUOO466nzKQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWxKCjdozYGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SCC_w4NxzYZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rO-9YLR0zYc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J-fFXjJUzYf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8uEXsJX8zKTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FCI**"
      ],
      "metadata": {
        "id": "2CVP3J8PEbfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from causallearn.search.ConstraintBased.FCI import fci\n",
        "from causallearn.graph.GraphNode import GraphNode\n",
        "from causallearn.utils.PCUtils.BackgroundKnowledge import BackgroundKnowledge"
      ],
      "metadata": {
        "id": "tPvO5Iaj3Mua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate confounded data\n",
        "N = 1000\n",
        "\n",
        "q = np.random.uniform(0, 2, N)\n",
        "w = np.random.randn(N)\n",
        "x = np.random.gumbel(0, 1, N) + w\n",
        "y = 0.6 * q + 0.8 * w + np.random.uniform(0, 1, N)\n",
        "z = 0.5 * x + np.random.randn(N)\n",
        "\n",
        "data = np.stack([x, y, w, z, q]).T\n",
        "confounded_data = np.stack([x, y, z, q]).T"
      ],
      "metadata": {
        "id": "4lvwRV2ZE0Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the true graph\n",
        "nodes = ['X', 'Y', 'W', 'Z', 'Q']\n",
        "\n",
        "edges = [\n",
        "    ('W', 'X'),\n",
        "    ('W', 'Y'),\n",
        "    ('Q', 'Y'),\n",
        "    ('X', 'Z'),\n",
        "]\n",
        "\n",
        "fci_graph = nx.DiGraph()\n",
        "\n",
        "fci_graph.add_nodes_from(nodes)\n",
        "fci_graph.add_edges_from(edges)"
      ],
      "metadata": {
        "id": "Zj5bKuoAFEpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the graph\n",
        "plt.figure(figsize=(4, 3))\n",
        "\n",
        "nx.draw_networkx(\n",
        "    G=fci_graph,\n",
        "    node_color=COLORS[0],\n",
        "    node_size=1200,\n",
        "    nodelist=['X', 'Y', 'Z', 'Q'],\n",
        "    arrowsize=17,\n",
        "    with_labels=True,\n",
        "    font_color='white',\n",
        "    font_size=21,\n",
        "    pos=nx.circular_layout(fci_graph)\n",
        ")\n",
        "nx.draw_networkx(\n",
        "    G=fci_graph,\n",
        "    node_color=COLORS[1],\n",
        "    node_size=1200,\n",
        "    nodelist=['W'],\n",
        "    arrowsize=17,\n",
        "    with_labels=True,\n",
        "    font_color='white',\n",
        "    font_size=21,\n",
        "    pos=nx.circular_layout(fci_graph)\n",
        ")"
      ],
      "metadata": {
        "id": "Ff3ZZTZgFHrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_causal = df_causal.drop(columns=['slope_ttc'])"
      ],
      "metadata": {
        "id": "hGcAdBG5NcqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "D9PX2RryzkIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train FCI and get the graph\n",
        "g, edges = fci(\n",
        "    dataset=df_causal.values,\n",
        "    independence_test_method='kci'\n",
        ")"
      ],
      "metadata": {
        "id": "xPTd8zswFXp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordering: [x, y, z, q]\n",
        "g.graph\n",
        "GraphDAG(g.causal_matrix)"
      ],
      "metadata": {
        "id": "gsGRjXQ6FbBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {\n",
        "    'X1': 'X',\n",
        "    'X2': 'Y',\n",
        "    'X3': 'Z',\n",
        "    'X4': 'Q'\n",
        "}\n",
        "\n",
        "for edge in edges:\n",
        "    mapped = str(edge)\\\n",
        "        .replace(str(edge.node1), mapping[str(edge.node1)])\\\n",
        "        .replace(str(edge.node2), mapping[str(edge.node2)])\n",
        "    print(mapped)"
      ],
      "metadata": {
        "id": "1rolMa5EFeV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(edge), str(edge.node1)"
      ],
      "metadata": {
        "id": "nfrv_mMsFh-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model with prior knowledge"
      ],
      "metadata": {
        "id": "h2NhhygMzru3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add prior knowledge\n",
        "prior_knowledge = BackgroundKnowledge()\n",
        "prior_knowledge.add_forbidden_by_node(GraphNode('X2'), GraphNode('X4'))\n",
        "prior_knowledge.add_required_by_node(GraphNode('X1'), GraphNode('X3'))\n",
        "\n",
        "g, edges = fci(\n",
        "    dataset=confounded_data,\n",
        "    independence_test_method='fisherz',\n",
        "    background_knowledge=prior_knowledge\n",
        ")"
      ],
      "metadata": {
        "id": "R22NRxO5FmQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for edge in edges:\n",
        "    mapped = str(edge)\\\n",
        "        .replace(str(edge.node1), mapping[str(edge.node1)])\\\n",
        "        .replace(str(edge.node2), mapping[str(edge.node2)])\n",
        "    print(mapped)"
      ],
      "metadata": {
        "id": "LnOeQZQTFp4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uIHsrrEXzyPt"
      }
    }
  ]
}